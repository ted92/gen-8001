\section{Introduction}
%todo: talk about main difficulties in open research data in our field
%todo: IDENTIFY these difficulties
Before the advent of scientific journals,
science was more oriented towards a closed approach, so that only a restricted number
of people could have access to it.
Many scientists, including Galileo, Newton, Kepler, and Hooke, made their discoveries into
something they could profit, and often papers were even encoded in anagrams.
Following this closed science logic, it was difficult
to identify scientific priority of research discoveries, like for instance the
debate on whom first discovered calculus between Leibniz and Newton.

In modern times, scientific research is moving towards openness,
and technology has solved scientific priority issue to a certain extent.
Many scientists are in favor of open science, for instance
Merton argues that knowledge-creation is more efficient if scientists work together, and
it is morally binding on a professional scientist\,\cite{merton1942science}.
However, there exists research data, journals, and papers which are not openly accessible.
In some cases research data is not available due to privacy concerns.
Research data collected by for-profit organizations is held in secrecy, for
safeguarding commercial interests.
Furthermore, pay-walled journals limit access of scientific publications.
All this hinders the propagation of open science.

%go from reproducibility to physics then cs and then machine learning, and stick with it!
Besides seeking knowledge, science needs also to constantly proof itself
to be right, hence it needs to be \emph{reproducible}. 
In sixteenth and seventeenth centuries, scientists such as Newton or Galileo could guarantee
reproducibility in physics by using mathematical formulas.
%
In the late twentieth century, in the field of \ac{cs},
\emph{pseudo code}\footnote{pseudo code is the logic or abstraction which explains algorithms.}
helped reproducibility.

In twenty-first century, \ac{ml} rapidly gained popularity\,\cite{mjolsness2001machine}.
\ac{ml} relies on new techniques based on big data analysis and statistical inference.
With \ac{ml} it is possible to train machines to solve particular tasks without being
given specific instructions.
%
\ac{ml} has drastically changed the way of doing research\,\cite{anderson2008end},
so that mathematical formulas and pseudo code are not
enough to guarantee reproducibility, while research data, source code,
and model's set up, became fundamental information in order to reconstruct the
same outcomes of an experiment.

In this manuscript we want to enhance the main challenges related to reproducibility
in \ac{ml}. More importance should be given to open source
code and open research data, in order to perform good science.
Excessively closed research data can lead to reproducibility issues,
especially when big data analysis is involved.

% you need to tune parameters
\section{Reproducibility Issue and Open Science}
Scientific discoveries suffer of reproducibility due
to selective reporting, selective analysis, or insufficient specification to recreate the
expected results\,\cite{aarts2016reproducibility}. 
In \ac{ml}, these specifications include tuning parameters for statistical models, 
which result to be crucial for reproducibility. Furthermore, tuning parameters
is a very sensitive issue both in practical applications and in academic studies\,\cite{birattari2004problem}.

Besides there are still many published researches outside the field of \ac{ml} which cannot be
reproduced\,\cite{begley2012drug, begley2015reproducibility, prinz2011believe},
the degree of openness that \ac{ml} requires in order to have a reproducible research, is making
transparency and open science a key point for reproducibility.
Howerver, some researchers are not willing to share code and data\,\cite{gundersen2018state}.
In a study conducted by Colleberg and Proebsting\,\cite{Collberg:2016:RCS:2897191.2812803},
even in open access journals, such as \ac{acm}, only $66\%$ of the experimental papers
were backed by code and only $32\%$ of those were easily reproducible.
Following the study of Gundersen\,\cite{gundersen2018state},
conducted in other conferences, out of $400$ algorithms presented,
$54\%$ included pseudo code, $30\%$ included test data, and only the $6\%$
included the source code.

Our interest in this manuscript relies on research data, and \ac{ml} does not only require the raw dataset.
To be fully reproducible, the research needs to share also \emph{training data}, \emph{validation data},
\emph{test data}, and \emph{results}. The same survey from
Grundesen\,\cite{gundersen2018state}, conducted on papers from \ac{ijcai} and \ac{aaai}, enhanced that
only the training set was shared by the majority, with a score of $56\%$, while test, validation and results
got respectively a low score of $30\%$, $16\%$, and $4\%$.

Being blockchain technology and cryptocurrencies our domain,
data are public, hence after performing a research in dataset search engines, such as
Dataverse\,\cite{crosas2011dataverse} or Google Dataset
Search\footnote{https://toolbox.google.com/datasetsearch},
we found the information we needed, openly available. However, experiments involving \ac{ml} models
over large datasets are time consuming and expensive to run. Then the main
challenges for open research data in \ac{ml} are the lack of time and the cost of sharing data.

%todo: show which data are not shared --> then claim why in the conclusion

%todo: add also source code and ML tuning parameters
%todo: enhance the key point of this section: ehnance a search on research data and show the main challenges for sharing research data

% sharing of public health research data has potential to advance scientific progress but may present challenges to the interests of research stakeholders, particularly in low-to-middle income countries\,\cite{jao2015involving}

% Regulatory agencies are generally obligated to protect the commercial value of the data collected by companies\,\cite{national2016principles}.

%todo: insert this --> closed models or data can slow down the scientific process, hence the progress

%todo: check on google datasets search

\section{Conclusions}
% especially in \ac{cs} and \ac{ml} we believe that reproducibility in science is the key value that should enable data and source code to be shared. Data need to be shared if results want to be reproduced, hence confirm the scientific discovery
Furthermore, regulatory agencies are generally obligated to protect the commercial
value of the data collected by companies\,\cite{national2016principles}.

Reproduce a \ac{ml} experiment needs also the complete dataset, from the raw data to the
training, test, and validation set, and 
%todo: some data are sensitive and needs to be preserved and protected.

% todo: talk about privacy online and how open access can affect the resarch or reserachers in certain fileds
%todo: different open science schools\,\cite{Fecher2014}

%\newpage
% Bibliography
\bibliographystyle{acm}
\bibliography{bibliography}
