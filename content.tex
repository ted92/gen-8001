\section{Introduction}
%todo: talk about main difficulties in open research data in our field
%todo: IDENTIFY these difficulties
Before the advent of scientific journals,
science was more oriented towards a closed approach, so that only a restricted number
of people could have access to it.
Many scientists, including Galileo, Newton, Kepler, and Hooke, made their discoveries into
something they could profit, and often papers were even encoded in anagrams.
Following this closed science logic, it was difficult
to identify scientific priority of research discoveries, like for instance the
debate on whom first discovered calculus between Leibniz and Newton.

In modern times, scientific research is moving towards openness,
and technology has solved scientific priority issue to a certain extent.
Many scientists are in favor of open science, for instance
Merton argues that knowledge-creation is more efficient if scientists work together, and
it is morally binding on a professional scientist\,\cite{merton1942science}.
However, there exists research data, journals, and papers which are not openly accessible.
In some cases research data is not available due to privacy concerns.
Research data collected by for-profit organizations is held in secrecy, for
safeguarding commercial interests.
Furthermore, pay-walled journals limit access of scientific publications.
All this hinders the propagation of open science.

%go from reproducibility to physics then cs and then machine learning, and stick with it!
Besides seeking knowledge, science needs also to constantly proof itself
to be right, hence it needs to be \emph{reproducible}. 
In sixteenth and seventeenth centuries, scientists such as Newton or Galileo could guarantee
reproducibility in physics by using mathematical formulas.
%
In the late twentieth century, in the field of \ac{cs},
\emph{pseudo code}\footnote{pseudo code is the logic or abstraction which explains algorithms.}
helped reproducibility.

In twenty-first century, \ac{ml} rapidly gained popularity\,\cite{mjolsness2001machine}.
\ac{ml} relies on new techniques based on big data analysis and statistical inference.
With \ac{ml} it is possible to train machines to solve particular tasks without being
given specific instructions.
%
\ac{ml} has drastically changed the way of doing research\,\cite{anderson2008end},
so that mathematical formulas and pseudo code are not
enough to guarantee reproducibility, while research data, source code,
and model's set up, became fundamental information in order to reconstruct the
same outcomes of an experiment.

In this manuscript we want to enhance the main challenges related to reproducibility
in \ac{ml}. More importance should be given to open source
code and open research data, in order to perform good science.
Excessively closed research data can lead to reproducibility issues,
especially when big data analysis is involved.

% you need to tune parameters
\section{Reproducibility Issue and Open Science}
Scientific discoveries suffer of reproducibility due
to selective reporting, selective analysis, or insufficient specification to recreate the
expected results\,\cite{aarts2016reproducibility}. 
In \ac{ml}, these specifications include tuning parameters for statistical models, 
which result to be crucial for reproducibility. Furthermore, tuning parameters
is a very sensitive issue both in practical applications and in academic studies\,\cite{birattari2004problem}.

Besides there are still many published researches outside the field of \ac{ml} which cannot be
reproduced\,\cite{begley2012drug, begley2015reproducibility, prinz2011believe},
the degree of openness that \ac{ml} requires in order to have a reproducible research, is making
transparency and open science a key point for reproducibility.
Howerver, some researchers are not willing to share code and data\,\cite{gundersen2018state}.
In a study conducted by Colleberg and Proebsting\,\cite{Collberg:2016:RCS:2897191.2812803},
even in open access journals, such as \ac{acm}, only $66\%$ of the experimental papers
were backed by code and only $32\%$ of those were easily reproducible.
Following the study of Gundersen\,\cite{gundersen2018state},
conducted in other conferences, out of $400$ algorithms presented,
$54\%$ included pseudo code, $30\%$ included test data, and only the $6\%$
included the source code.

Our interest in this manuscript relies on research data, and \ac{ml} does not only require the raw dataset.
To be fully reproducible, the research needs to share also \emph{training data}, \emph{validation data},
\emph{test data}, and \emph{results}. The same survey from
Grundesen\,\cite{gundersen2018state}, conducted on papers from \ac{ijcai} and \ac{aaai}, enhanced that
only the training set was shared by the majority, with a score of $56\%$, while test, validation and results
got respectively a low score of $30\%$, $16\%$, and $4\%$.

Being blockchain technology and cryptocurrencies our domain,
data are public, hence after performing a research in dataset search engines, such as
Dataverse\,\cite{crosas2011dataverse} or Google Dataset
Search\footnote{https://toolbox.google.com/datasetsearch},
we found the information we needed, openly available. However, experiments involving \ac{ml} models
over large datasets are time consuming and expensive to run. We derive that the main
challenges for publishing open research data in \ac{ml} are the excessive time for training and
depositing big data, and the costs of running experiments to produce results and validation set.

\section{Conclusions}
We agree that open science is beneficial in order to conduct good scientific research,
and we have seen that to have full reproducibility in \ac{ml}, research data must be open.
To speed up the scientific process, it is fundamental to make available also bad data samples, even if
they are often evicted from the final presented work.
However, even with open data, infrastructure costs and lack of time can hinder reproducibility.
Encouraging the use of open research data is not enough for a good use of it. For each subject of study,
there should be national guidelines to assist researchers in warranted methods for open research data.
Furthermore, we believe that open science methodology and approaches should
be part of the young researchers' curriculum.

%Open science methodology should also be part of the curriculum for young researchers.
% especially in \ac{cs} and \ac{ml} we believe that reproducibility in science is the key value that should enable data and source code to be shared. Data need to be shared if results want to be reproduced, hence confirm the scientific discovery
Even if openness of research data will speed up the scientific process,
while enabling reproducibility, there are still many cases where openness is not
possible. For instance, regulatory agencies are generally obligated to protect the commercial
value of the data collected by companies\,\cite{national2016principles}.
Information contained in datasets should also comply with the normative on privacy preserving,
and data anonymization is often recommended. Furthermore, scientific researches
commissioned by private companies will benefit in keeping secrecy on their research data.

Finally, we think that is preferable, for the sake of science and progress, to keep an high
level of openness. Disciplines such as \ac{ml} should be transparent concerning source code
and research data. We have shown that closed models or data, can slow
down the scientific process, hence the progress.

%\newpage
% Bibliography
\bibliographystyle{acm}
\bibliography{bibliography}
